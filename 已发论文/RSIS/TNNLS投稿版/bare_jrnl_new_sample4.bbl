% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{bib1}
N.~Bobroff, ``Position measurement with a resolution and noise-limited instrument,'' \emph{Review of Scientific Instruments}, vol.~57, no.~6, pp. 1152--1157, 1986.

\bibitem{bib2}
N.~Pavlidou, A.~H. Vinck, J.~Yazdani, and B.~Honary, ``Power line communications: state of the art and future trends,'' \emph{IEEE Communications magazine}, vol.~41, no.~4, pp. 34--40, 2003.

\bibitem{bib3}
D.~Cabric, S.~M. Mishra, and R.~W. Brodersen, ``Implementation issues in spectrum sensing for cognitive radios,'' in \emph{Conference Record of the Thirty-Eighth Asilomar Conference on Signals, Systems and Computers, 2004.}, vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax Ieee, 2004, pp. 772--776.

\bibitem{bib4}
D.~Karimi, H.~Dou, S.~K. Warfield, and A.~Gholipour, ``Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis,'' \emph{Medical image analysis}, vol.~65, p. 101759, 2020.

\bibitem{bib5}
W.~Jiang, ``Applications of deep learning in stock market prediction: recent progress,'' \emph{Expert Systems with Applications}, vol. 184, p. 115537, 2021.

\bibitem{bib6}
S.~L. Ullo and G.~R. Sinha, ``Advances in smart environment monitoring systems using iot and sensors,'' \emph{Sensors}, vol.~20, no.~11, p. 3113, 2020.

\bibitem{bib7}
X.~Chu, I.~F. Ilyas, S.~Krishnan, and J.~Wang, ``Data cleaning: Overview and emerging challenges,'' in \emph{Proceedings of the 2016 international conference on management of data}, 2016, pp. 2201--2206.

\bibitem{bib8}
L.~Berti-Equille, T.~Dasu, and D.~Srivastava, ``Discovery of complex glitch patterns: A novel approach to quantitative data cleaning,'' in \emph{2011 IEEE 27th International Conference on Data Engineering}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2011, pp. 733--744.

\bibitem{bib9}
A.~Buades, B.~Coll, and J.-M. Morel, ``Non-local means denoising,'' \emph{Image Processing On Line}, vol.~1, pp. 208--212, 2011.

\bibitem{bib10}
A.~M. Wink and J.~B. Roerdink, ``Denoising functional mr images: a comparison of wavelet denoising and gaussian smoothing,'' \emph{IEEE transactions on medical imaging}, vol.~23, no.~3, pp. 374--387, 2004.

\bibitem{bib11}
M.~Lukasik, S.~Bhojanapalli, A.~Menon, and S.~Kumar, ``Does label smoothing mitigate label noise?'' in \emph{International Conference on Machine Learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2020, pp. 6448--6458.

\bibitem{bib12}
C.~Liguori, A.~Paolillo, A.~Ruggiero, and D.~Russo, ``Outlier detection for the evaluation of the measurement uncertainty of environmental acoustic noise,'' \emph{IEEE Transactions on Instrumentation and Measurement}, vol.~65, no.~2, pp. 234--242, 2015.

\bibitem{bib13}
U.~Habib, G.~Zucker, M.~Blochle, F.~Judex, and J.~Haase, ``Outliers detection method using clustering in buildings data,'' in \emph{IECON 2015-41st Annual Conference of the IEEE Industrial Electronics Society}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2015, pp. 000\,694--000\,700.

\bibitem{bib14}
J.~W. Osborne, \emph{Best practices in data cleaning: A complete guide to everything you need to do before and after collecting your data}.\hskip 1em plus 0.5em minus 0.4em\relax Sage publications, 2012.

\bibitem{bib15}
M.~N.~K. Sikder and F.~A. Batarseh, ``Outlier detection using ai: a survey,'' \emph{AI Assurance}, pp. 231--291, 2023.

\bibitem{bib19}
F.~B. Hildebrand, \emph{Introduction to numerical analysis}.\hskip 1em plus 0.5em minus 0.4em\relax Courier Corporation, 1987.

\bibitem{bib20}
J.-P. Lewis, ``Algorithms for solid noise synthesis,'' in \emph{Proceedings of the 16th annual conference on Computer graphics and interactive techniques}, 1989, pp. 263--270.

\bibitem{bib21}
H.~Zhang, M.~Cisse, Y.~N. Dauphin, and D.~Lopez-Paz, ``mixup: Beyond empirical risk minimization,'' \emph{arXiv preprint arXiv:1710.09412}, 2017.

\bibitem{bib22}
D.~Walawalkar, Z.~Shen, Z.~Liu, and M.~Savvides, ``Attentive cutmix: An enhanced data augmentation approach for deep learning based image classification,'' \emph{arXiv preprint arXiv:2003.13048}, 2020.

\bibitem{bib23}
C.~P. Robert, G.~Casella, and G.~Casella, \emph{Monte Carlo statistical methods}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 1999, vol.~2.

\bibitem{bib25}
A.~Bhosekar and M.~Ierapetritou, ``Advances in surrogate based modeling, feasibility analysis, and optimization: A review,'' \emph{Computers \& Chemical Engineering}, vol. 108, pp. 250--267, 2018.

\bibitem{bib26}
N.~Nasios and A.~G. Bors, ``Variational learning for gaussian mixture models,'' \emph{IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, vol.~36, no.~4, pp. 849--862, 2006.

\bibitem{bib27}
N.~Friedman, M.~Goldszmidt, and T.~J. Lee, ``Bayesian network classification with continuous attributes: Getting the best of both discretization and parametric fitting.'' in \emph{ICML}, vol.~98.\hskip 1em plus 0.5em minus 0.4em\relax Citeseer, 1998, pp. 179--187.

\bibitem{bib28}
O.~Arandjelovic and R.~Cipolla, ``Incremental learning of temporally-coherent gaussian mixture models,'' 2005.

\bibitem{bib30}
G.~M. Raab, B.~Nowok, and C.~Dibben, ``Practical data synthesis for large samples,'' \emph{Journal of Privacy and Confidentiality}, vol.~7, no.~3, pp. 67--97, 2016.

\bibitem{bib31}
H.~Ling and K.~Okada, ``Diffusion distance for histogram comparison,'' in \emph{2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)}, vol.~1.\hskip 1em plus 0.5em minus 0.4em\relax IEEE, 2006, pp. 246--253.

\bibitem{bib32}
Y.-J. Oyang, S.-C. Hwang, Y.-Y. Ou, C.-Y. Chen, and Z.-W. Chen, ``Data classification with radial basis function networks based on a novel kernel density estimation algorithm,'' \emph{IEEE transactions on neural networks}, vol.~16, no.~1, pp. 225--236, 2005.

\bibitem{bib33}
N.~V. Chawla, K.~W. Bowyer, L.~O. Hall, and W.~P. Kegelmeyer, ``Smote: synthetic minority over-sampling technique,'' \emph{Journal of artificial intelligence research}, vol.~16, pp. 321--357, 2002.

\bibitem{bib34}
Y.~Tang, Y.-Q. Zhang, N.~V. Chawla, and S.~Krasser, ``Svms modeling for highly imbalanced classification,'' \emph{IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)}, vol.~39, no.~1, pp. 281--288, 2008.

\bibitem{bib35}
M.~Mukherjee and M.~Khushi, ``Smote-enc: A novel smote-based method to generate synthetic data for nominal and continuous features,'' \emph{Applied System Innovation}, vol.~4, no.~1, p.~18, 2021.

\bibitem{bib36}
T.~Salimans, I.~Goodfellow, W.~Zaremba, V.~Cheung, A.~Radford, and X.~Chen, ``Improved techniques for training gans,'' \emph{Advances in neural information processing systems}, vol.~29, 2016.

\bibitem{bib37}
H.~Alqahtani, M.~Kavakli-Thorne, and G.~Kumar, ``Applications of generative adversarial networks (gans): An updated review,'' \emph{Archives of Computational Methods in Engineering}, vol.~28, pp. 525--552, 2021.

\bibitem{bib38}
A.~Creswell, T.~White, V.~Dumoulin, K.~Arulkumaran, B.~Sengupta, and A.~A. Bharath, ``Generative adversarial networks: An overview,'' \emph{IEEE signal processing magazine}, vol.~35, no.~1, pp. 53--65, 2018.

\bibitem{bib39}
S.~Bond-Taylor, A.~Leach, Y.~Long, and C.~G. Willcocks, ``Deep generative modelling: A comparative review of vaes, gans, normalizing flows, energy-based and autoregressive models,'' \emph{IEEE transactions on pattern analysis and machine intelligence}, vol.~44, no.~11, pp. 7327--7347, 2021.

\bibitem{bib40}
K.~Sohn, H.~Lee, and X.~Yan, ``Learning structured output representation using deep conditional generative models,'' \emph{Advances in neural information processing systems}, vol.~28, 2015.

\bibitem{bib41}
M.~Li, J.~Lin, Y.~Ding, Z.~Liu, J.-Y. Zhu, and S.~Han, ``Gan compression: Efficient architectures for interactive conditional gans,'' in \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, 2020, pp. 5284--5294.

\bibitem{bib42}
P.~Isola, J.-Y. Zhu, T.~Zhou, and A.~A. Efros, ``Image-to-image translation with conditional adversarial networks,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2017, pp. 1125--1134.

\bibitem{bib43}
A.~Van Den~Oord, N.~Kalchbrenner, and K.~Kavukcuoglu, ``Pixel recurrent neural networks,'' in \emph{International conference on machine learning}.\hskip 1em plus 0.5em minus 0.4em\relax PMLR, 2016, pp. 1747--1756.

\bibitem{bib44}
A.~Van~den Oord, N.~Kalchbrenner, L.~Espeholt, O.~Vinyals, A.~Graves \emph{et~al.}, ``Conditional image generation with pixelcnn decoders,'' \emph{Advances in neural information processing systems}, vol.~29, 2016.

\bibitem{bib46}
T.~Elguebaly and N.~Bouguila, ``Bayesian learning of finite generalized gaussian mixture models on images,'' \emph{Signal Processing}, vol.~91, no.~4, pp. 801--820, 2011.

\bibitem{bib47}
S.~J. Roberts, D.~Husmeier, I.~Rezek, and W.~Penny, ``Bayesian approaches to gaussian mixture modeling,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol.~20, no.~11, pp. 1133--1142, 1998.

\bibitem{bib48}
H.~Xu and H.~Zha, ``A dirichlet mixture model of hawkes processes for event sequence clustering,'' \emph{Advances in neural information processing systems}, vol.~30, 2017.

\bibitem{bib49}
N.~Bouguila and D.~Ziou, ``A dirichlet process mixture of generalized dirichlet distributions for proportional data modeling,'' \emph{IEEE Transactions on Neural Networks}, vol.~21, no.~1, pp. 107--122, 2009.

\bibitem{bib51}
S.~Hong, D.~Yang, J.~Choi, and H.~Lee, ``Inferring semantic layout for hierarchical text-to-image synthesis,'' in \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, 2018, pp. 7986--7994.

\bibitem{bib53}
M.~M. Breunig, H.-P. Kriegel, R.~T. Ng, and J.~Sander, ``Lof: identifying density-based local outliers,'' in \emph{Proceedings of the 2000 ACM SIGMOD international conference on Management of data}, 2000, pp. 93--104.

\bibitem{bib56}
M.~J{\"u}nger, G.~Reinelt, and G.~Rinaldi, ``The traveling salesman problem,'' \emph{Handbooks in operations research and management science}, vol.~7, pp. 225--330, 1995.

\bibitem{bib57}
N.~M. Razali, J.~Geraghty \emph{et~al.}, ``Genetic algorithm performance with different selection strategies in solving tsp,'' in \emph{Proceedings of the world congress on engineering}, vol.~2, no.~1.\hskip 1em plus 0.5em minus 0.4em\relax International Association of Engineers Hong Kong, China, 2011, pp. 1--6.

\bibitem{bib61}
A.~R. Barron, A.~Cohen, W.~Dahmen, and R.~A. DeVore, ``Approximation and learning by greedy algorithms,'' 2008.

\bibitem{bib64}
{\c{S}}.~G{\"u}lc{\"u}, M.~Mahi, {\"O}.~K. Baykan, and H.~Kodaz, ``A parallel cooperative hybrid method based on ant colony optimization and 3-opt algorithm for solving traveling salesman problem,'' \emph{Soft Computing}, vol.~22, pp. 1669--1685, 2018.

\bibitem{bib70}
Q.~Sun and Z.~Ge, ``A survey on deep learning for data-driven soft sensors,'' \emph{IEEE Transactions on Industrial Informatics}, vol.~17, no.~9, pp. 5853--5866, 2021.

\bibitem{bib71}
P.~Kadlec, R.~Grbi{\'c}, and B.~Gabrys, ``Review of adaptation mechanisms for data-driven soft sensors,'' \emph{Computers \& chemical engineering}, vol.~35, no.~1, pp. 1--24, 2011.

\bibitem{bib82}
Y.~Guo, W.~Wang, and X.~Wang, ``A robust linear regression feature selection method for data sets with unknown noise,'' \emph{IEEE Transactions on Knowledge and Data Engineering}, vol.~35, no.~1, pp. 31--44, 2021.

\bibitem{bib83}
G.~Wu, R.~Mallipeddi, P.~N. Suganthan, R.~Wang, and H.~Chen, ``Differential evolution with multi-population based ensemble of mutation strategies,'' \emph{Information Sciences}, vol. 329, pp. 329--345, 2016.

\bibitem{bib84}
\BIBentryALTinterwordspacing
W.~Cukierski, ``Bike sharing demand,'' 2014. [Online]. Available: \url{https://kaggle.com/competitions/bike-sharing-demand}
\BIBentrySTDinterwordspacing

\bibitem{bib85}
S.~Vito, ``{Air Quality},'' UCI Machine Learning Repository, 2016, {DOI}: https://doi.org/10.24432/C59K5F.

\bibitem{bib86}
S.~Moro, P.~Rita, and B.~Vala, ``{Facebook metrics},'' UCI Machine Learning Repository, 2016, {DOI}: https://doi.org/10.24432/C5QK55.

\bibitem{bib87}
P.~Cortez and A.~Morais, ``{Forest Fires},'' UCI Machine Learning Repository, 2008, {DOI}: https://doi.org/10.24432/C5D88D.

\bibitem{bib88}
Y.~LeCun, L.~Bottou, Y.~Bengio, and P.~Haffner, ``Gradient-based learning applied to document recognition,'' \emph{Proceedings of the IEEE}, vol.~86, no.~11, pp. 2278--2324, 1998.

\bibitem{bib89}
H.~Xiao, K.~Rasul, and R.~Vollgraf. (2017) Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.

\bibitem{bib90}
A.~Krizhevsky, G.~Hinton \emph{et~al.}, ``Learning multiple layers of features from tiny images,'' 2009.

\bibitem{bib91}
Y.~Netzer, T.~Wang, A.~Coates, A.~Bissacco, B.~Wu, A.~Y. Ng \emph{et~al.}, ``Reading digits in natural images with unsupervised feature learning,'' in \emph{NIPS workshop on deep learning and unsupervised feature learning}, vol. 2011, no.~5.\hskip 1em plus 0.5em minus 0.4em\relax Granada, Spain, 2011, p.~7.

\end{thebibliography}
